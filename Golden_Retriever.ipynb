{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Query Augmentation Tool: A Context-Aware Query Refinement System\n",
        "\n",
        "The **Query Augmentation Tool** is an AI-driven workflow that enhances the accuracy and relevance of responses to user queries by identifying abbreviations, determining context, expanding terms, and refining queries. Built using the LangChain and LangGraph frameworks, this tool processes user inputs through a sequence of specialized agents, ensuring that abbreviations are accurately expanded, queries are aligned with specific contexts, and responses are optimized for effectiveness.\n",
        "\n",
        "## Overview\n",
        "\n",
        "The core functionality of the Query Augmentation Tool includes:\n",
        "\n",
        "- **Identifying Abbreviations** in user queries, essential for interpreting field-specific terminology.\n",
        "- **Determining Query Context** to distinguish fields such as Medicine, AI, or Technology.\n",
        "- **Providing Context-Specific Definitions** by referencing a specialized knowledge base.\n",
        "- **Augmenting the Query** when necessary to make it more comprehensive, allowing an LLM to generate a highly relevant response.\n",
        "\n",
        "## Key Objectives\n",
        "\n",
        "This tool is tailored to meet critical requirements in technical and academic environments where:\n",
        "\n",
        "- **Precision in Query Interpretation**: By detecting abbreviations and determining context, the tool clarifies ambiguous terms that vary across fields.\n",
        "- **Query Enhancement**: By dynamically refining the original query, the tool ensures that the query aligns closely with user intent, leading to more accurate responses.\n",
        "- **Optimized Response Generation**: By enriching the query with specific context, the tool improves the relevance and quality of LLM responses.\n",
        "\n",
        "## Workflow Structure\n",
        "\n",
        "The Query Augmentation Tool is implemented as a structured graph of agents, each performing a unique function in the query enhancement pipeline:\n",
        "\n",
        "1. **Jargon Agent**\n",
        "   - **Purpose**: Scans the user query for abbreviations or shorthand terms.\n",
        "   - **Output**: If abbreviations are found, they are tagged with a prefix, `ABBREVIATIONS_USED`; if no abbreviations are detected, the response is `NO_ABBREVIATIONS_USED_IN_QUERY`.\n",
        "   - **Utility**: This initial step ensures any abbreviations are flagged early, preparing the query for accurate context matching.\n",
        "\n",
        "2. **Context Agent**\n",
        "   - **Purpose**: Assigns the most relevant context for the query from predefined options (e.g., \"Medical,\" \"Technology,\" \"AI\").\n",
        "   - **Output**: Tags the output with `CONTEXT_MATCHED` and the identified context, such as `CONTEXT_MATCHED: Medical`.\n",
        "   - **Utility**: Correct context assignment allows for precise interpretation of abbreviations, especially terms with varied meanings across fields.\n",
        "\n",
        "3. **Search Agent**\n",
        "   - **Purpose**: Searches for definitions or meanings of abbreviations based on the identified context.\n",
        "   - **Output**: Returns the definition if a match is found in the context-specific dictionary; if not, it responds with `NO SUCH WORD EXISTS, PLEASE CHECK SPELLING`.\n",
        "   - **Utility**: Accurate abbreviation expansion is ensured by conducting a targeted search within the correct context.\n",
        "\n",
        "4. **New Query Agent**\n",
        "   - **Purpose**: Enhances the original query by integrating contextually relevant information. If no term matches, it modifies the query based on internal resources.\n",
        "   - **Output**: Returns a refined query prefixed with `NEW_QUERY`, optimized for downstream LLM response generation.\n",
        "   - **Utility**: This agent bridges the gap between user intent and system response, tailoring the query to drive accurate LLM-generated answers.\n",
        "\n",
        "## Example Workflow Execution\n",
        "\n",
        "**Input Query**: “I am doing medical research. Tell me about RAG.”\n",
        "\n",
        "1. **Jargon Agent** detects \"RAG\" as an abbreviation.\n",
        "2. **Context Agent** identifies \"Medical\" as the context based on the query.\n",
        "3. **Search Agent** retrieves the medical definition of \"RAG\" (e.g., \"Reproductive Anisole Generation\").\n",
        "4. **New Query Agent** augments the query to “Tell me about Reproductive Anisole Generation in a medical context,” ensuring relevance.\n",
        "\n",
        "## Implementation Details\n",
        "\n",
        "This workflow leverages LangChain's `ChatOpenAI` for model interaction and LangGraph for stateful graph management. Key implementation details include:\n",
        "\n",
        "- **Function Definitions**: Each agent is implemented as a unique function, processing input and returning results with specific tags.\n",
        "- **Graph Workflow**: The state graph, managed by LangGraph, directs the query through each agent sequentially, with each agent as a node.\n",
        "\n",
        "### Key Dependencies\n",
        "\n",
        "Install required libraries with:\n",
        "\n",
        "```bash\n",
        "!pip install langgraph langchain_community\n",
        "!pip install langchain_openai\n",
        "%pip install -qU duckduckgo-search langchain-community\n",
        "```\n",
        "\n",
        "### Usage Considerations\n",
        "\n",
        "This tool is ideal for scenarios where:\n",
        "\n",
        "- Context-specific abbreviations frequently occur.\n",
        "- High precision in query interpretation is required, especially in specialized research.\n",
        "- Enhanced query structure improves the accuracy and relevance of AI-generated responses.\n",
        "\n",
        "### Future Enhancements\n",
        "\n",
        "Potential updates to the Query Augmentation Tool include:\n",
        "\n",
        "- **Dynamic Context Expansion**: Automatically adding new contexts or definitions from external knowledge sources.\n",
        "- **Interactive Query Refinement**: Enabling users to verify or adjust context selections.\n",
        "- **Real-Time Feedback Mechanism**: Introducing a feedback loop for continuous learning based on user interactions."
      ],
      "metadata": {
        "id": "fCTDv1iOXEUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaQBZ1dt4F-m",
        "outputId": "2c6bfb6d-ce20-4e95-e37b-66adccb18402"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (0.2.45)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.5)\n",
            "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.3.15)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from langgraph) (2.0.2)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.32 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.1.35)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.10)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.7)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.139)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.6->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.6->langchain_community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph) (0.27.2)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2.0.36,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain_community) (2.23.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9xb8hhg3ql1",
        "outputId": "e292f727-ec37-4208-fa60-1ecca92a7c57"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.2.6-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.3.15)\n",
            "Collecting openai<2.0.0,>=1.54.0 (from langchain_openai)\n",
            "  Downloading openai-1.54.3-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (0.1.139)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (4.66.6)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain_openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain_openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_openai) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_openai) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.2.3)\n",
            "Downloading langchain_openai-0.2.6-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.54.3-py3-none-any.whl (389 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.6/389.6 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, openai, langchain_openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.52.2\n",
            "    Uninstalling openai-1.52.2:\n",
            "      Successfully uninstalled openai-1.52.2\n",
            "Successfully installed langchain_openai-0.2.6 openai-1.54.3 tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU duckduckgo-search langchain-community"
      ],
      "metadata": {
        "id": "lzZ1R_gJNhC8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xJRooKRq22U6"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"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\"\n",
        "os.environ[\"TAVILY_API_KEY\"] =\"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\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdeQYuLp3laZ",
        "outputId": "0cb0a871-cd3f-436f-abee-a29da871b5f5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import (\n",
        "    BaseMessage,\n",
        "    HumanMessage,\n",
        "    ToolMessage,\n",
        ")\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "from langgraph.graph import END, StateGraph, START\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Updated create_jargon_agent\n",
        "def create_jargon_agent(llm):\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
        "                \"Your task is to identify any abbreviations or shorthands in the original user query.\"\n",
        "                \"If abbreviations are detected, pass them with the prefix 'ABBREVIATIONS_USED:'.\"\n",
        "                \"If no abbreviations are detected, pass 'NO_ABBREVIATIONS_USED_IN_QUERY:' along with the original user query.\"\n",
        "                \"You can access the original user query as needed for this identification.\"\n",
        "            ),\n",
        "            MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        ]\n",
        "    )\n",
        "    return prompt | llm\n",
        "\n",
        "# Updated create_context_agent\n",
        "def create_context_agent(llm, CONTEXTS: list):\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                \"You are a helpful assistant, tasked with identifying the context from a list: {CONTEXTS}.\"\n",
        "                \"Identify the matching context based on the original user'query\"\n",
        "                \"Original Query: {original_query}\"\n",
        "                \" and return it prefixed with 'CONTEXT_MATCHED:' \"\n",
        "                \"along with the response from the previous assistant.\"\n",
        "                \"You can directly access the original user query and CONTEXTS for this process.\"\n",
        "                \"Strictly , you don't have to return any definition or description about abbreviation or user's query.\"\n",
        "                \"Just return contex matched.\"\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "    prompt = prompt.partial(CONTEXTS=CONTEXTS)\n",
        "    return prompt | llm\n",
        "\n",
        "# Updated create_search_agent\n",
        "def create_search_agent(llm, QUERY: dict):\n",
        "    \"\"\"Create an agent that retrieves definitions based on context.\"\"\"\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
        "                \"You have only one task to do.\"\n",
        "                \"Read the CONTEXT and ABBREVIATIONS received from the previous assistant.\"\n",
        "                \"Original Query: {original_query}\"\n",
        "                \"Use this dictionary {QUERY} to check if any matching abbreviation or shorthand definitions \"\n",
        "                \"are relevant to the context derived from the previous assistant.\"\n",
        "                \"If a matching abbreviation in this context is found, return its definition; \"\n",
        "                \"otherwise, respond with: NO SUCH WORD EXISTS, PLEASE CHECK SPELLING.\"\n",
        "            ),\n",
        "            MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        ]\n",
        "    )\n",
        "    prompt = prompt.partial(QUERY=QUERY)\n",
        "    return prompt | llm\n",
        "\n",
        "\n",
        "# Updated create_new_query_agent\n",
        "def create_new_query_agent(llm):\n",
        "    \"\"\"Create an agent that adjusts the user's query based on context.\"\"\"\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
        "                \"Your task is to adjust the original query if necessary.\"\n",
        "                \"Original Query: {original_query}\"\n",
        "                \"If the previous assistant responded with 'NO SUCH WORD EXISTS, PLEASE CHECK SPELLING', \"\n",
        "                \"use your internal knowledge to gather information on the abbreviation in the query in that particular context or field only.\"\n",
        "                \"Otherwise, enhance the query based on information provided by the previous assistant \"\n",
        "                \"to make it clearer for the next assistant.\"\n",
        "                \"Return the modified query prefixed with 'NEW_QUERY:'.\"\n",
        "            ),\n",
        "            MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        ]\n",
        "    )\n",
        "    return prompt | llm"
      ],
      "metadata": {
        "id": "P8Pz4q8c3oay"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "from typing import Annotated, Sequence\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "# This defines the object that is passed between each node\n",
        "# in the graph. We will create different nodes for each agent and tool\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "    sender: str\n",
        "    original_query: str  # Store the original user query here"
      ],
      "metadata": {
        "id": "E2ygH6j8A1FJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "\n",
        "from langchain_core.messages import AIMessage\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "search = DuckDuckGoSearchRun()\n",
        "tool_node = ToolNode([search])\n",
        "\n",
        "\n",
        "# Helper function to create a node for a given agent with dynamic tool binding\n",
        "def agent_node(state, agent, name, tools=None):\n",
        "    # Ensure the agent has access to the original query from the state\n",
        "    state[\"original_query\"] = state.get(\"original_query\", \"\")\n",
        "\n",
        "    # Invoke the agent with the current state (including original query)\n",
        "    result = agent.invoke(state)\n",
        "\n",
        "    # Format the result to be compatible with the global state\n",
        "    if isinstance(result, ToolMessage):\n",
        "        pass\n",
        "    else:\n",
        "        # Append the name of the current node to the AIMessage\n",
        "        result = AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
        "\n",
        "    return {\n",
        "        \"messages\": [result],\n",
        "        # Include original query for use by next agent in the workflow\n",
        "        \"original_query\": state[\"original_query\"],\n",
        "        \"sender\": name,\n",
        "    }\n",
        "\n",
        "\n",
        "CONTEXTS = ['Medical ','Technology','AI']\n",
        "QUERY={\n",
        "    'AI' : {'RAG': \"means Retrieval Augmented Generation\",\n",
        "            'DAG':\"means Dynamic Augmented Graph\"\n",
        "            },\n",
        "    'Medical' : {\n",
        "        'RAG': \"means Reproductive Anisole Generation , which is a new mode of reproduction identified recently\"\n",
        "    },\n",
        "    }\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "\n",
        "# Research agent and node\n",
        "jargon_agent = create_jargon_agent(\n",
        "    llm,\n",
        ")\n",
        "jargon_node = functools.partial(agent_node, agent=jargon_agent, name=\"Jargon\")\n",
        "\n",
        "# chart_generator\n",
        "context_agent = create_context_agent(\n",
        "    llm,\n",
        "    CONTEXTS,\n",
        ")\n",
        "context_node = functools.partial(agent_node, agent=context_agent, name=\"context\")\n",
        "\n",
        "\n",
        "search_agent = create_search_agent(\n",
        "    llm,\n",
        "    QUERY,\n",
        ")\n",
        "search_node = functools.partial(agent_node, agent=search_agent, name=\"search\")\n",
        "\n",
        "\n",
        "new_query_agent = create_new_query_agent(\n",
        "    llm\n",
        ")\n",
        "new_query_node = functools.partial(agent_node, agent=new_query_agent, name=\"new_query\")"
      ],
      "metadata": {
        "id": "X9jCktVtA2Th"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Either agent can decide to end\n",
        "from typing import Literal\n",
        "\n",
        "\n",
        "def router(state):\n",
        "    # This is the router\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "    if last_message.tool_calls:\n",
        "        # The previous agent is invoking a tool\n",
        "        return \"call_tool\"\n",
        "    return \"continue\""
      ],
      "metadata": {
        "id": "yLs_qxq6GUbS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "workflow.add_node(\"jargoner\", jargon_node)\n",
        "workflow.add_node(\"contextor\", context_node)\n",
        "workflow.add_node(\"searcher\", search_node)\n",
        "workflow.add_node(\"new_querier\", new_query_node)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfym0bnVBQ7B",
        "outputId": "cfea6a6b-5c47-466a-e3ae-d0ccdcd00d96"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7ce918c74c10>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "workflow.add_edge(START, \"jargoner\")\n",
        "workflow.add_edge(\"jargoner\", \"contextor\")\n",
        "workflow.add_edge(\"contextor\", \"searcher\")\n",
        "workflow.add_edge(\"searcher\", \"new_querier\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ju1rGjtjFI6F",
        "outputId": "4a163482-c6af-49a7-cc25-5e352cea2296"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7ce918c74c10>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph = workflow.compile()"
      ],
      "metadata": {
        "id": "pCxJLmlcFWnx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "TQ4CWUfVFd_L",
        "outputId": "6ac87dfb-4d98-4d79-cfdd-c93c3e28ee98"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "events = graph.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            HumanMessage(content=\"i am doing medical research . tell me about RAG\")  # User query provided here\n",
        "        ],\n",
        "        \"sender\": \"user\",\n",
        "        \"original_query\": \"i am doing medical research . tell me about RAG\",  # Store original query here in state\n",
        "    },\n",
        "    {\"recursion_limit\": 150},\n",
        ")\n",
        "\n",
        "\n",
        "# Process and print events\n",
        "for s in events:\n",
        "    print(s)\n",
        "    print(\"----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41n_39oIFgDc",
        "outputId": "d7dd9f5e-63ab-4bec-8db9-ef0c7268f6e0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'jargoner': {'messages': [AIMessage(content='ABBREVIATIONS_USED: RAG', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 107, 'total_tokens': 115, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_159d8341cc', 'finish_reason': 'stop', 'logprobs': None}, name='Jargon', id='run-349cb814-ab12-4c3d-a885-47c44b0bf619-0', usage_metadata={'input_tokens': 107, 'output_tokens': 8, 'total_tokens': 115, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})], 'sender': 'Jargon', 'original_query': 'i am doing medical research . tell me about RAG'}}\n",
            "----\n",
            "{'contextor': {'messages': [AIMessage(content='CONTEXT_MATCHED: Medical', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 115, 'total_tokens': 121, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_45cf54deae', 'finish_reason': 'stop', 'logprobs': None}, name='context', id='run-3feb382e-3bb5-4f86-8f29-dad614a45c4d-0', usage_metadata={'input_tokens': 115, 'output_tokens': 6, 'total_tokens': 121, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})], 'sender': 'context', 'original_query': 'i am doing medical research . tell me about RAG'}}\n",
            "----\n",
            "{'searcher': {'messages': [AIMessage(content='RAG means Reproductive Anisole Generation, which is a new mode of reproduction identified recently.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 197, 'total_tokens': 217, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_159d8341cc', 'finish_reason': 'stop', 'logprobs': None}, name='search', id='run-3a8cd707-8522-4407-8e42-c999b68e198a-0', usage_metadata={'input_tokens': 197, 'output_tokens': 20, 'total_tokens': 217, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})], 'sender': 'search', 'original_query': 'i am doing medical research . tell me about RAG'}}\n",
            "----\n",
            "{'new_querier': {'messages': [AIMessage(content='NEW_QUERY: I am doing medical research. Can you provide information on RAG genes, particularly their role in the immune system and any relevance they might have to medical research?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 182, 'total_tokens': 217, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_45cf54deae', 'finish_reason': 'stop', 'logprobs': None}, name='new_query', id='run-d69c9a5e-81b8-4312-87ec-8d22c10b1dc7-0', usage_metadata={'input_tokens': 182, 'output_tokens': 35, 'total_tokens': 217, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})], 'sender': 'new_query', 'original_query': 'i am doing medical research . tell me about RAG'}}\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aWqXKrPGFuXi"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}